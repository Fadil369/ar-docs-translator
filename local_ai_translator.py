#!/usr/bin/env python3
"""
Local AI-Enhanced Translation Engine
Advanced translation system without API key requirements.

Features:
- Comprehensive Arabic technical terminology database
- Context-aware translation patterns
- Advanced linguistic processing
- GitHub-specific domain knowledge
- Smart content structure analysis
- Natural language enhancement rules
"""

import os
import re
import json
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from collections import defaultdict

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class LocalAITranslator:
    """Advanced local translator with AI-like intelligence"""
    
    def __init__(self, docs_root: Optional[str] = None, aggressive: bool = False, arabic_only: bool = False):
        # Resolve docs_root relative to this script if not absolute
        script_dir = Path(__file__).parent
        if docs_root is None:
            self.docs_root = (script_dir / "docs").resolve()
        else:
            candidate = Path(docs_root)
            self.docs_root = (candidate if candidate.is_absolute() else (script_dir / candidate)).resolve()
        self.content_root = self.docs_root / "content"
        self.aggressive = aggressive
        self.arabic_only = arabic_only
        self.fallback_threshold = 0.6 if aggressive else 0.25
        
        # Initialize translation databases
        self.setup_terminology_database()
        self.setup_linguistic_rules()
        self.setup_content_patterns()
        self.setup_github_domain_knowledge()
        self.setup_lexical_fallback()
        
        # Statistics tracking
        self.stats = {
            "files_processed": 0,
            "translations_enhanced": 0,
            "terminology_applications": 0,
            "pattern_matches": 0,
            "linguistic_improvements": 0
        }

    def setup_lexical_fallback(self):
        """High-frequency Englishâ†’Arabic lexical mappings for offline translation."""
        self.lexical_map: Dict[str, str] = {
            # Pronouns / helpers
            "you": "Ø£Ù†Øª",
            "your": "Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ",
            "we": "Ù†Ø­Ù†",
            "they": "Ù‡Ù…",
            "it": "Ù‡Ùˆ",
            "this": "Ù‡Ø°Ø§",
            "that": "Ø°Ù„Ùƒ",
            "these": "Ù‡Ø°Ù‡",
            "those": "ØªÙ„Ùƒ",
            "is": "Ù‡Ùˆ",
            "are": "Ù‡ÙŠ",
            "was": "ÙƒØ§Ù†",
            "were": "ÙƒØ§Ù†Øª",
            "be": "ÙŠÙƒÙˆÙ†",
            "been": "ÙƒØ§Ù†",
            "will": "Ø³ÙˆÙ",
            "should": "ÙŠØ¬Ø¨",
            "must": "ÙŠØ¬Ø¨",
            "can": "ÙŠÙ…ÙƒÙ†",
            "could": "ÙŠÙ…ÙƒÙ†",
            "may": "Ù‚Ø¯",
            "might": "Ù‚Ø¯",
            "not": "Ù„ÙŠØ³",
            "and": "Ùˆ",
            "or": "Ø£Ùˆ",
            "but": "Ù„ÙƒÙ†",
            "if": "Ø¥Ø°Ø§",
            "when": "Ø¹Ù†Ø¯",
            "where": "Ø­ÙŠØ«",
            "how": "ÙƒÙŠÙ",
            "what": "Ù…Ø§",
            "why": "Ù„Ù…Ø§Ø°Ø§",
            "to": "Ø¥Ù„Ù‰",
            "from": "Ù…Ù†",
            "for": "Ù„Ù€",
            "with": "Ù…Ø¹",
            "without": "Ø¨Ø¯ÙˆÙ†",
            "in": "ÙÙŠ",
            "on": "Ø¹Ù„Ù‰",
            "by": "Ø¨ÙˆØ§Ø³Ø·Ø©",
            "of": "Ù…Ù†",
            "as": "ÙƒÙ€",
            "about": "Ø­ÙˆÙ„",
            "before": "Ù‚Ø¨Ù„",
            "after": "Ø¨Ø¹Ø¯",
            "between": "Ø¨ÙŠÙ†",
            "within": "Ø¶Ù…Ù†",
            "using": "Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù…",
            "into": "Ø¥Ù„Ù‰",
            "over": "ÙÙˆÙ‚",
            "under": "ØªØ­Øª",
            "through": "Ø¹Ø¨Ø±",
            "via": "Ø¹Ø¨Ø±",

            # Common UI/actions
            "create": "Ø¥Ù†Ø´Ø§Ø¡",
            "created": "ØªÙ… Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡",
            "delete": "Ø­Ø°Ù",
            "deleted": "ØªÙ… Ø§Ù„Ø­Ø°Ù",
            "update": "ØªØ­Ø¯ÙŠØ«",
            "updated": "ØªÙ… Ø§Ù„ØªØ­Ø¯ÙŠØ«",
            "edit": "ØªØ­Ø±ÙŠØ±",
            "open": "ÙØªØ­",
            "close": "Ø¥ØºÙ„Ø§Ù‚",
            "closed": "Ù…ØºÙ„Ù‚",
            "click": "Ø§Ù†Ù‚Ø±",
            "select": "Ø­Ø¯Ø¯",
            "choose": "Ø§Ø®ØªØ±",
            "go": "Ø§Ø°Ù‡Ø¨",
            "enable": "ØªÙ…ÙƒÙŠÙ†",
            "enabled": "Ù…ÙÙ…ÙƒÙ‘Ù†",
            "disable": "ØªØ¹Ø·ÙŠÙ„",
            "disabled": "Ù…ÙØ¹Ø·Ù‘Ù„",
            "configure": "ØªÙƒÙˆÙŠÙ†",
            "settings": "Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª",
            "setting": "Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯",
            "manage": "Ø¥Ø¯Ø§Ø±Ø©",
            "management": "Ø¥Ø¯Ø§Ø±Ø©",
            "view": "Ø¹Ø±Ø¶",
            "see": "Ø§Ù†Ø¸Ø±",
            "learn": "ØªØ¹Ù„Ù…",
            "install": "ØªØ«Ø¨ÙŠØª",
            "upgrade": "ØªØ±Ù‚ÙŠØ©",
            "sign": "ØªØ³Ø¬ÙŠÙ„",
            "sign in": "ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„",
            "sign out": "ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬",
            "log in": "ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„",
            "log out": "ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬",
            "save": "Ø­ÙØ¸",
            "apply": "ØªØ·Ø¨ÙŠÙ‚",
            "run": "ØªØ´ØºÙŠÙ„",
            "build": "Ø¨Ù†Ø§Ø¡",
            "test": "Ø§Ø®ØªØ¨Ø§Ø±",
            "deploy": "Ù†Ø´Ø±",
            "publish": "Ù†Ø´Ø±",
            "allows": "ÙŠØ³Ù…Ø­",
            "allow": "ÙŠØ³Ù…Ø­",
            "exchange": "ØªØ¨Ø§Ø¯Ù„",
            "short-lived": "Ù‚ØµÙŠØ±Ø© Ø§Ù„Ø£Ø¬Ù„",
            "directly": "Ù…Ø¨Ø§Ø´Ø±Ø©",
            "cloud": "Ø§Ù„Ø³Ø­Ø§Ø¨Ø©",
            "provider": "Ø§Ù„Ù…Ø²ÙˆÙ‘Ø¯",
            "providers": "Ø§Ù„Ù…Ø²ÙˆÙ‘Ø¯ÙˆÙ†",
            "in your": "ÙÙŠ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ",
            "before you begin": "Ù‚Ø¨Ù„ Ø£Ù† ØªØ¨Ø¯Ø£",
            "at this stage": "ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø©",
            "for example": "Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„",
            "by updating": "Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªØ­Ø¯ÙŠØ«",
            "by default": "Ø§ÙØªØ±Ø§Ø¶ÙŠÙ‹Ø§",
            "to get started": "Ù„Ù„Ø¨Ø¯Ø¡",
            "you can now": "ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¢Ù†",
            "next steps": "Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©",
            "use": "Ø§Ø³ØªØ®Ø¯Ù…",
            "usage": "Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…",
            "instruction": "ØªØ¹Ù„ÙŠÙ…Ø§Øª",
            "instructions": "ØªØ¹Ù„ÙŠÙ…Ø§Øª",
            "installing": "ØªØ«Ø¨ÙŠØª",
            "package": "Ø­Ø²Ù…Ø©",
            "packages": "Ø­Ø²Ù…",
            "dependency": "Ø§Ø¹ØªÙ…Ø§Ø¯ÙŠØ©",
            "dependencies": "Ø§Ø¹ØªÙ…Ø§Ø¯ÙŠØ§Øª",
            "search": "Ø§Ø¨Ø­Ø«",
            "find": "Ø§Ù„Ø¹Ø«ÙˆØ±",
            "supported": "Ù…Ø¯Ø¹ÙˆÙ…",
            "client": "Ø¹Ù…ÙŠÙ„",
            "instance": "Ù…Ø«ÙŠÙ„",
            "specific": "Ù…Ø­Ø¯Ø¯",
            "working": "Ø§Ù„Ø¹Ù…Ù„",
            "registry": "Ø§Ù„Ø³Ø¬Ù„",
            "billing": "Ø§Ù„ÙÙˆØªØ±Ø©",
            "platform": "Ø§Ù„Ù…Ù†ØµØ©",
            "roles": "Ø£Ø¯ÙˆØ§Ø±",
            "role": "Ø¯ÙˆØ±",
            "promotion": "Ø¹Ø±Ø¶ ØªØ±ÙˆÙŠØ¬ÙŠ",
            "promotions": "Ø¹Ø±ÙˆØ¶ ØªØ±ÙˆÙŠØ¬ÙŠØ©",
            "discount": "Ø®ØµÙ…",
            "discounts": "Ø®ØµÙˆÙ…Ø§Øª",
            "csv": "CSV",
            "report": "ØªÙ‚Ø±ÙŠØ±",
            "reports": "ØªÙ‚Ø§Ø±ÙŠØ±",
            "codeql": "CodeQL",
            "cli": "CLI",
            "database": "Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª",
            "analyze": "ØªØ­Ù„ÙŠÙ„",
            "bundle": "Ø­Ø²Ù…Ø©",
            "cleanup": "ØªÙ†Ø¸ÙŠÙ",
            "import": "Ø§Ø³ØªÙŠØ±Ø§Ø¯",
            "export": "ØªØµØ¯ÙŠØ±",
            "finalize": "Ø¥Ù†Ù‡Ø§Ø¡",
            "resolve": "Ø­Ù„",
            "query": "Ø§Ø³ØªØ¹Ù„Ø§Ù…",
            "format": "ØªÙ†Ø³ÙŠÙ‚",
            "metadata": "Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØµÙÙŠØ©",
            "version": "Ø¥ØµØ¯Ø§Ø±",
            "server": "Ø®Ø§Ø¯Ù…",
            "language": "Ù„ØºØ©",
            "pack": "Ø­Ø²Ù…Ø©",
            "upgrade": "ØªØ±Ù‚ÙŠØ©",
            "decompile": "ÙÙƒ ØªØ¬Ù…ÙŠØ¹",
            "token": "Ø±Ù…Ø²",
            "endpoint": "Ù†Ù‚Ø·Ø© Ù†Ù‡Ø§ÙŠØ©",
            "endpoints": "Ù†Ù‚Ø§Ø· Ù†Ù‡Ø§ÙŠØ©",
            "available": "Ù…ØªØ§Ø­Ø©",
            "access": "ÙˆØµÙˆÙ„",
            "chat": "Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©",
            "configure": "ØªÙƒÙˆÙŠÙ†",
            "manage": "Ø¥Ø¯Ø§Ø±Ø©",
            "decode": "ÙÙƒ ØªØ±Ù…ÙŠØ²",
            "hash": "ØªØ¬Ø²Ø¦Ø©",
            "interpret": "ØªÙØ³ÙŠØ±",
            "diagnostic": "ØªØ´Ø®ÙŠØµ",
            "diagnostics": "ØªØ´Ø®ÙŠØµØ§Øª",
            "dataset": "Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª",
            "datasets": "Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¨ÙŠØ§Ù†Ø§Øª",
            "measure": "Ù‚ÙŠØ§Ø³",
            "predicate": "Ù…Ø³Ù†Ø¯",
            "extensible": "Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªÙˆØ³Ø¹Ø©",
            "execute": "ØªÙ†ÙÙŠØ°",
            "generate": "Ø¥Ù†Ø´Ø§Ø¡",
            "help": "Ù…Ø³Ø§Ø¹Ø¯Ø©",
            "add": "Ø¥Ø¶Ø§ÙØ©",
            "viewing": "Ø¹Ø±Ø¶",
            "description": "ÙˆØµÙ",
            "data": "Ø¨ÙŠØ§Ù†Ø§Øª",
            "bypass": "ØªØ¬Ø§ÙˆØ²",
            "delegated": "Ù…ÙÙˆÙ‘Ø¶",
            "protection": "Ø­Ù…Ø§ÙŠØ©",
            "push": "Ø¯ÙØ¹",
            "upgrades": "ØªØ±Ù‚ÙŠØ§Øª",
            "synchronization": "Ù…Ø²Ø§Ù…Ù†Ø©",
            "synchronize": "Ù…Ø²Ø§Ù…Ù†Ø©",
            "time synchronization": "Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„ÙˆÙ‚Øª",
            "deleting": "Ø­Ø°Ù",
            "library": "Ù…ÙƒØªØ¨Ø©",
            "libraries": "Ù…ÙƒØªØ¨Ø§Øª",
            "insights": "Ø±Ø¤Ù‰",
            "exporting": "ØªØµØ¯ÙŠØ±",

            # Nouns common in GitHub docs
            "account": "Ø§Ù„Ø­Ø³Ø§Ø¨",
            "profile": "Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø´Ø®ØµÙŠ",
            "organization": "Ø§Ù„Ù…Ù†Ø¸Ù…Ø©",
            "user": "Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…",
            "members": "Ø§Ù„Ø£Ø¹Ø¶Ø§Ø¡",
            "member": "Ø§Ù„Ø¹Ø¶Ùˆ",
            "owner": "Ø§Ù„Ù…Ø§Ù„Ùƒ",
            "team": "Ø§Ù„ÙØ±ÙŠÙ‚",
            "project": "Ø§Ù„Ù…Ø´Ø±ÙˆØ¹",
            "settings": "Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª",
            "preferences": "Ø§Ù„ØªÙØ¶ÙŠÙ„Ø§Øª",
            "email": "Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ",
            "security": "Ø§Ù„Ø£Ù…Ø§Ù†",
            "privacy": "Ø§Ù„Ø®ØµÙˆØµÙŠØ©",
            "permissions": "Ø§Ù„Ø£Ø°ÙˆÙ†Ø§Øª",
            "access": "Ø§Ù„ÙˆØµÙˆÙ„",
            "token": "Ø§Ù„Ø±Ù…Ø²",
            "password": "ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±",
            "passkey": "Ù…ÙØªØ§Ø­ Ø§Ù„Ù…Ø±ÙˆØ±",
            "branch": "ÙØ±Ø¹",
            "branches": "ÙØ±ÙˆØ¹",
            "commit": "Ø§Ù„ØªØ²Ø§Ù…",
            "issue": "Ù‚Ø¶ÙŠØ©",
            "pull": "Ø³Ø­Ø¨",
            "request": "Ø·Ù„Ø¨",
            "workflow": "Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„",
            "runner": "Ù…Ø´ØºÙ„",
            "artifact": "Ù…Ù†ØªØ¬",
            "actions": "Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª",
            "copilot": "Copilot",
            "codespaces": "Codespaces",
            "overview": "Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©",
            "summary": "Ø§Ù„Ù…Ù„Ø®Øµ",
            "prerequisites": "Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ø³Ø¨Ù‚Ø©",
            "warning": "ØªØ­Ø°ÙŠØ±",
            "caution": "ØªØ­Ø°ÙŠØ±",
            "tip": "Ù†ØµÙŠØ­Ø©",
            "note": "Ù…Ù„Ø§Ø­Ø¸Ø©",
        }

    def _arabic_ratio(self, text: str) -> float:
        total_letters = len(re.findall(r"[A-Za-z\u0600-\u06FF]", text))
        if total_letters == 0:
            return 1.0
        arabic_letters = len(re.findall(r"[\u0600-\u06FF]", text))
        return arabic_letters / total_letters

    def _apply_lexical_fallback(self, text: str) -> str:
        # Apply word-level replacements conservatively with word boundaries
        result = text
        for en, ar in self.lexical_map.items():
            pattern = r"\b" + re.escape(en) + r"\b"
            result = re.sub(pattern, ar, result, flags=re.IGNORECASE)
        return result

    def _arabic_typography(self, text: str) -> str:
        # Apply Arabic typography only on lines containing Arabic
        digit_map = str.maketrans("0123456789", "Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©")
        out_lines: List[str] = []
        for line in text.splitlines():
            if re.search(r"[\u0600-\u06FF]", line):
                l = line.translate(digit_map)
                l = l.replace("?", "ØŸ").replace(";", "Ø›").replace(",", "ØŒ")
                l = re.sub(r"[ \t]+", " ", l)
                out_lines.append(l)
            else:
                out_lines.append(line)
        return "\n".join(out_lines)

    def _arabic_only_cleanup(self, text: str) -> str:
        # Remove fenced and inline code, liquid, URLs/emails, HTML tags
        cleaned = re.sub(r"```[\s\S]*?```", "", text)
        cleaned = re.sub(r"`[^`]+`", "", cleaned)
        cleaned = re.sub(r"({%[^%]*%}|{{[^}]*}})", "", cleaned)
        cleaned = re.sub(r"https?://\S+", "", cleaned)
        cleaned = re.sub(r"\b\S+@\S+\b", "", cleaned)
        cleaned = re.sub(r"<[^>]+>", " ", cleaned)

        # Drop Latin letters; keep digits and punctuation for now
        cleaned = re.sub(r"[A-Za-z]", "", cleaned)

        # Keep only lines with Arabic content
        kept_lines: List[str] = []
        for line in cleaned.splitlines():
            ln = line.strip()
            if not ln:
                continue
            if re.search(r"[\u0600-\u06FF]", ln):
                kept_lines.append(ln)

        result = "\n".join(kept_lines)
        result = re.sub(r"\n{3,}", "\n\n", result).strip()
        # Apply Arabic typography at the end
        return self._arabic_typography(result)
    
    def setup_terminology_database(self):
        """Comprehensive technical terminology database"""
        
        self.terminology = {
            # Core GitHub Terms
            "repository": "Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹",
            "repositories": "Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹Ø§Øª", 
            "commit": "Ø§Ù„Ø§Ù„ØªØ²Ø§Ù…",
            "commits": "Ø§Ù„Ø§Ù„ØªØ²Ø§Ù…Ø§Øª",
            "pull request": "Ø·Ù„Ø¨ Ø§Ù„Ø³Ø­Ø¨",
            "pull requests": "Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ø³Ø­Ø¨",
            "issue": "Ø§Ù„Ù‚Ø¶ÙŠØ©",
            "issues": "Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§",
            "branch": "Ø§Ù„ÙØ±Ø¹",
            "branches": "Ø§Ù„ÙØ±ÙˆØ¹",
            "merge": "Ø§Ù„Ø¯Ù…Ø¬",
            "fork": "Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…ØªÙØ±Ø¹Ø©",
            "clone": "Ø§Ù„Ø§Ø³ØªÙ†Ø³Ø§Ø®",
            "push": "Ø§Ù„Ø¯ÙØ¹",
            "fetch": "Ø§Ù„Ø¬Ù„Ø¨",
            "workflow": "Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„",
            "workflows": "Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„",
            
            # Authentication & Security
            "authentication": "Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø©",
            "authorization": "Ø§Ù„ØªØ®ÙˆÙŠÙ„",
            "token": "Ø§Ù„Ø±Ù…Ø² Ø§Ù„Ù…Ù…ÙŠØ²",
            "tokens": "Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ù…Ù…ÙŠØ²Ø©",
            "API key": "Ù…ÙØªØ§Ø­ API",
            "SSH key": "Ù…ÙØªØ§Ø­ SSH",
            "OAuth": "OAuth",
            "two-factor authentication": "Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø© Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ù„",
            "2FA": "Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø© Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ù„",
            "passkey": "Ù…ÙØªØ§Ø­ Ø§Ù„Ù…Ø±ÙˆØ±",
            "passkeys": "Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ù…Ø±ÙˆØ±",
            "single sign-on": "ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ù…ÙˆØ­Ø¯",
            "SSO": "ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ù…ÙˆØ­Ø¯",
            
            # Actions & CI/CD
            "GitHub Actions": "GitHub Actions",
            "action": "Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡",
            "actions": "Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª",
            "runner": "Ø§Ù„Ù…Ø´ØºÙ„",
            "runners": "Ø§Ù„Ù…Ø´ØºÙ„ÙˆÙ†",
            "job": "Ø§Ù„Ù…Ù‡Ù…Ø©",
            "jobs": "Ø§Ù„Ù…Ù‡Ø§Ù…",
            "step": "Ø§Ù„Ø®Ø·ÙˆØ©",
            "steps": "Ø§Ù„Ø®Ø·ÙˆØ§Øª",
            "artifact": "Ø§Ù„Ù…Ù†ØªØ¬",
            "artifacts": "Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª",
            "deployment": "Ø§Ù„Ù†Ø´Ø±",
            "continuous integration": "Ø§Ù„ØªÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ø³ØªÙ…Ø±",
            "CI/CD": "CI/CD",
            "build": "Ø§Ù„Ø¨Ù†Ø§Ø¡",
            
            # Organizations & Teams
            "organization": "Ø§Ù„Ù…Ù†Ø¸Ù…Ø©",
            "organizations": "Ø§Ù„Ù…Ù†Ø¸Ù…Ø§Øª",
            "team": "Ø§Ù„ÙØ±ÙŠÙ‚",
            "teams": "Ø§Ù„ÙØ±Ù‚",
            "member": "Ø§Ù„Ø¹Ø¶Ùˆ",
            "members": "Ø§Ù„Ø£Ø¹Ø¶Ø§Ø¡",
            "owner": "Ø§Ù„Ù…Ø§Ù„Ùƒ",
            "admin": "Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„",
            "collaborator": "Ø§Ù„Ù…ØªØ¹Ø§ÙˆÙ†",
            "collaborators": "Ø§Ù„Ù…ØªØ¹Ø§ÙˆÙ†ÙˆÙ†",
            
            # Development Terms
            "code": "Ø§Ù„ÙƒÙˆØ¯",
            "source code": "Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ØµØ¯Ø±ÙŠ",
            "codebase": "Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„ÙƒÙˆØ¯",
            "developer": "Ø§Ù„Ù…Ø·ÙˆØ±",
            "developers": "Ø§Ù„Ù…Ø·ÙˆØ±ÙˆÙ†",
            "development": "Ø§Ù„ØªØ·ÙˆÙŠØ±",
            "programming": "Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©",
            "software": "Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ§Øª",
            "application": "Ø§Ù„ØªØ·Ø¨ÙŠÙ‚",
            "project": "Ø§Ù„Ù…Ø´Ø±ÙˆØ¹",
            "file": "Ø§Ù„Ù…Ù„Ù",
            "files": "Ø§Ù„Ù…Ù„ÙØ§Øª",
            "folder": "Ø§Ù„Ù…Ø¬Ù„Ø¯",
            "directory": "Ø§Ù„Ø¯Ù„ÙŠÙ„",
            
            # Git Terms
            "git": "Git",
            "version control": "Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„Ø¥ØµØ¯Ø§Ø±Ø§Øª",
            "staging": "Ø§Ù„ØªØ¬Ù‡ÙŠØ²",
            "stash": "Ø§Ù„Ù…Ø®Ø²Ù† Ø§Ù„Ù…Ø¤Ù‚Øª",
            "diff": "Ø§Ù„ÙØ±Ù‚",
            "log": "Ø§Ù„Ø³Ø¬Ù„",
            "remote": "Ø§Ù„Ø¨Ø¹ÙŠØ¯",
            "origin": "Ø§Ù„Ø£ØµÙ„",
            "upstream": "Ø§Ù„Ù…Ù†Ø¨Ø¹",
            "downstream": "Ø§Ù„Ù…ØµØ¨",
            
            # General Tech Terms
            "API": "API",
            "URL": "URL",
            "HTTP": "HTTP",
            "HTTPS": "HTTPS",
            "JSON": "JSON",
            "YAML": "YAML",
            "markdown": "Markdown",
            "command line": "Ø³Ø·Ø± Ø§Ù„Ø£ÙˆØ§Ù…Ø±",
            "terminal": "Ø§Ù„Ø·Ø±ÙÙŠØ©",
            "shell": "Ø§Ù„ØµØ¯ÙØ©",
            "script": "Ø§Ù„Ù†Øµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ",
            "configuration": "Ø§Ù„ØªÙƒÙˆÙŠÙ†",
            "settings": "Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª",
            "permissions": "Ø§Ù„Ø£Ø°ÙˆÙ†Ø§Øª",
            "access": "Ø§Ù„ÙˆØµÙˆÙ„",
            "security": "Ø§Ù„Ø£Ù…Ø§Ù†",
            "privacy": "Ø§Ù„Ø®ØµÙˆØµÙŠØ©",
            "token": "Ø±Ù…Ø² Ø§Ù„ÙˆØµÙˆÙ„",
            "access token": "Ø±Ù…Ø² Ø§Ù„ÙˆØµÙˆÙ„",
            "access tokens": "Ø±Ù…ÙˆØ² Ø§Ù„ÙˆØµÙˆÙ„",
            "user access token": "Ø±Ù…Ø² ÙˆØµÙˆÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…",
            "user access tokens": "Ø±Ù…ÙˆØ² ÙˆØµÙˆÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…",
            "installation access token": "Ø±Ù…Ø² ÙˆØµÙˆÙ„ Ø§Ù„ØªØ«Ø¨ÙŠØª",
            "installation access tokens": "Ø±Ù…ÙˆØ² ÙˆØµÙˆÙ„ Ø§Ù„ØªØ«Ø¨ÙŠØª",
            
            # Action Words
            "create": "Ø¥Ù†Ø´Ø§Ø¡",
            "delete": "Ø­Ø°Ù",
            "update": "ØªØ­Ø¯ÙŠØ«",
            "edit": "ØªØ­Ø±ÙŠØ±",
            "manage": "Ø¥Ø¯Ø§Ø±Ø©",
            "configure": "ØªÙƒÙˆÙŠÙ†",
            "setup": "Ø¥Ø¹Ø¯Ø§Ø¯",
            "install": "ØªØ«Ø¨ÙŠØª",
            "deploy": "Ù†Ø´Ø±",
            "publish": "Ù†Ø´Ø±",
            "share": "Ù…Ø´Ø§Ø±ÙƒØ©",
            "collaborate": "Ø§Ù„ØªØ¹Ø§ÙˆÙ†",
            "contribute": "Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø©",
            "review": "Ù…Ø±Ø§Ø¬Ø¹Ø©",
            "approve": "Ø§Ù„Ù…ÙˆØ§ÙÙ‚Ø©",
            "reject": "Ø±ÙØ¶",
            
            # Common Phrases
            "getting started": "Ø§Ù„Ø¨Ø¯Ø¡",
            "quick start": "Ø§Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ø³Ø±ÙŠØ¹",
            "learn more": "ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø²ÙŠØ¯",
            "read more": "Ø§Ù‚Ø±Ø£ Ø§Ù„Ù…Ø²ÙŠØ¯",
            "see also": "Ø§Ù†Ø¸Ø± Ø£ÙŠØ¶Ù‹Ø§",
            "for more information": "Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª",
            "best practices": "Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ù…Ø§Ø±Ø³Ø§Øª",
            "troubleshooting": "Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØ¥ØµÙ„Ø§Ø­Ù‡Ø§",
            "documentation": "Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª",
            "tutorial": "Ø§Ù„Ø¯Ø±Ø³ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ",
            "guide": "Ø§Ù„Ø¯Ù„ÙŠÙ„",
            "example": "Ù…Ø«Ø§Ù„",
            "examples": "Ø£Ù…Ø«Ù„Ø©",
            "libraries": "Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª",
            "network configurations": "ØªÙƒÙˆÙŠÙ†Ø§Øª Ø§Ù„Ø´Ø¨ÙƒØ©",
            "codes of conduct": "Ù…Ø¯ÙˆÙ†Ø§Øª Ø§Ù„Ø³Ù„ÙˆÙƒ",
            "code of conduct": "Ù…Ø¯ÙˆÙ†Ø© Ø§Ù„Ø³Ù„ÙˆÙƒ",
            "anti-bribery": "Ù…ÙƒØ§ÙØ­Ø© Ø§Ù„Ø±Ø´ÙˆØ©",
            "modern slavery": "Ø§Ù„Ø¹Ø¨ÙˆØ¯ÙŠØ© Ø§Ù„Ø­Ø¯ÙŠØ«Ø©",
            "child labor": "Ø¹Ù…Ù„ Ø§Ù„Ø£Ø·ÙØ§Ù„",
            "subprocessors": "Ù…Ø¹Ø§Ù„Ø¬Ø§Øª ÙØ±Ø¹ÙŠØ©",
            "subprocessor": "Ù…Ø¹Ø§Ù„Ø¬ ÙØ±Ø¹ÙŠ",
            "embeddings": "ØªØ¶Ù…ÙŠÙ†Ø§Øª",
            "keyboard shortcuts": "Ø§Ø®ØªØµØ§Ø±Ø§Øª Ù„ÙˆØ­Ø© Ø§Ù„Ù…ÙØ§ØªÙŠØ­",

            # Audit cue translations
            "overview": "Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©",
            "summary": "Ø§Ù„Ù…Ù„Ø®Øµ",
            "steps": "Ø§Ù„Ø®Ø·ÙˆØ§Øª",
            "prerequisites": "Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ø³Ø¨Ù‚Ø©",
            "note": "Ù…Ù„Ø§Ø­Ø¸Ø©",
            "tip": "Ù†ØµÙŠØ­Ø©",
            "caution": "ØªØ­Ø°ÙŠØ±",
            "warning": "ØªØ­Ø°ÙŠØ±",
            "this guide": "Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„",
            "about github": "Ø­ÙˆÙ„ GitHub"
            ,
            # Added phrase cues
            "in your": "ÙÙŠ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ",
            "before you begin": "Ù‚Ø¨Ù„ Ø£Ù† ØªØ¨Ø¯Ø£",
            "at this stage": "ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø©",
            "for example": "Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„",
            "by updating": "Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªØ­Ø¯ÙŠØ«",
            "by default": "Ø§ÙØªØ±Ø§Ø¶ÙŠÙ‹Ø§",
            "to get started": "Ù„Ù„Ø¨Ø¯Ø¡",
            "you can now": "ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¢Ù†",
            "next steps": "Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©"
        }
        
        # Create reverse mapping for context awareness
        self.reverse_terminology = {v: k for k, v in self.terminology.items()}
    
    def setup_linguistic_rules(self):
        """Advanced Arabic linguistic rules"""
        
        self.linguistic_rules = {
            # Article rules
            "definite_article": {
                "patterns": [
                    (r'\bthe\s+([a-zA-Z]+)', r'Ø§Ù„\1'),  # Basic "the" translation
                    (r'\ba\s+([a-zA-Z]+)', r'\1'),      # Remove indefinite articles
                    (r'\ban\s+([a-zA-Z]+)', r'\1')      # Remove indefinite articles
                ]
            },
            
            # Sentence structure improvements
            "sentence_structure": {
                "patterns": [
                    # Convert "You can..." to "ÙŠÙ…ÙƒÙ†Ùƒ..."
                    (r'\bYou can\s+([^.]+)', r'ÙŠÙ…ÙƒÙ†Ùƒ \1'),
                    # Convert "To do X..." to "Ù„Ù€..."
                    (r'\bTo\s+([a-zA-Z]+)', r'Ù„Ù€\1'),
                    # Convert "This will..." to "Ø³ÙŠØ¤Ø¯ÙŠ Ù‡Ø°Ø§ Ø¥Ù„Ù‰..."
                    (r'\bThis will\s+([^.]+)', r'Ø³ÙŠØ¤Ø¯ÙŠ Ù‡Ø°Ø§ Ø¥Ù„Ù‰ \1'),
                    # Convert "Learn how to..." to "ØªØ¹Ù„Ù… ÙƒÙŠÙÙŠØ©..."
                    (r'\bLearn how to\s+([^.]+)', r'ØªØ¹Ù„Ù… ÙƒÙŠÙÙŠØ© \1')
                ]
            },
            
            # Technical context patterns
            "technical_context": {
                "code_blocks": r'```[\s\S]*?```',
                "inline_code": r'`[^`]+`',
                "liquid_tags": r'{%[^%]*%}',
                "liquid_variables": r'{{[^}]*}}',
                "urls": r'https?://[^\s]+',
                "file_paths": r'[a-zA-Z0-9._/-]+\.[a-zA-Z]{2,4}'
            }
        }
    
    def setup_content_patterns(self):
        """Content structure and pattern recognition"""
        
        self.content_patterns = {
            # Common GitHub documentation patterns
            "introduction_patterns": [
                (r'^## About (.+)', r'## Ø­ÙˆÙ„ \1'),
                (r'^### What is (.+)\?', r'### Ù…Ø§ Ù‡Ùˆ \1ØŸ'),
                (r'^### Why (.+)\?', r'### Ù„Ù…Ø§Ø°Ø§ \1ØŸ'),
                (r'^### How (.+)', r'### ÙƒÙŠÙ \1'),
                (r'^### When (.+)', r'### Ù…ØªÙ‰ \1')
            ],
            
            "instruction_patterns": [
                (r'^### Step (\d+):', r'### Ø§Ù„Ø®Ø·ÙˆØ© \1:'),
                (r'^#### Prerequisites', r'#### Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ø³Ø¨Ù‚Ø©'),
                (r'^#### Requirements', r'#### Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª'),
                (r'^#### Before you begin', r'#### Ù‚Ø¨Ù„ Ø£Ù† ØªØ¨Ø¯Ø£'),
                (r'^### Next steps', r'### Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©')
            ],
            
            "navigation_patterns": [
                (r'In this article', r'ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù‚Ø§Ù„'),
                (r'Table of contents', r'Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙŠØ§Øª'),
                (r'See also', r'Ø§Ù†Ø¸Ø± Ø£ÙŠØ¶Ù‹Ø§'),
                (r'Related articles', r'Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©'),
                (r'Further reading', r'Ù‚Ø±Ø§Ø¡Ø© Ø¥Ø¶Ø§ÙÙŠØ©')
            ]
        }
    
    def setup_github_domain_knowledge(self):
        """GitHub-specific domain knowledge and context"""
        
        self.github_contexts = {
            # Product names (keep in English with Arabic explanation)
            "products": {
                "GitHub Desktop": "GitHub Desktop",
                "GitHub CLI": "GitHub CLI",
                "GitHub Mobile": "GitHub Mobile", 
                "GitHub Codespaces": "GitHub Codespaces",
                "GitHub Copilot": "GitHub Copilot",
                "GitHub Actions": "GitHub Actions",
                "GitHub Pages": "GitHub Pages",
                "GitHub Packages": "GitHub Packages"
            },
            
            # Feature explanations
            "feature_explanations": {
                "GitHub Desktop": "ØªØ·Ø¨ÙŠÙ‚ Ø³Ø·Ø­ Ø§Ù„Ù…ÙƒØªØ¨ Ù„Ù€ GitHub",
                "GitHub CLI": "ÙˆØ§Ø¬Ù‡Ø© Ø³Ø·Ø± Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ù„Ù€ GitHub", 
                "Codespaces": "Ø¨ÙŠØ¦Ø§Øª Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ø³Ø­Ø§Ø¨ÙŠØ©",
                "Copilot": "Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¨Ø±Ù…Ø¬Ø© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
                "Actions": "Ø£ØªÙ…ØªØ© Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„ ÙˆØ§Ù„ØªÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ø³ØªÙ…Ø±",
                "Pages": "Ø§Ø³ØªØ¶Ø§ÙØ© Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø«Ø§Ø¨ØªØ©",
                "Packages": "Ø¥Ø¯Ø§Ø±Ø© ÙˆØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø­Ø²Ù…"
            },
            
            # Common workflows
            "workflows": {
                "fork_and_pull": "Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ù…ØªÙØ±Ø¹ ÙˆØ·Ù„Ø¨ Ø§Ù„Ø³Ø­Ø¨",
                "gitflow": "Ø³ÙŠØ± Ø¹Ù…Ù„ Git",
                "feature_branch": "ÙØ±Ø¹ Ø§Ù„Ù…ÙŠØ²Ø©",
                "release_management": "Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¥ØµØ¯Ø§Ø±Ø§Øª"
            }
        }
    
    def extract_frontmatter(self, content):
        """Extract YAML frontmatter from markdown content"""
        if not content.strip().startswith('---'):
            return {}, content
            
        try:
            parts = content.split('---', 2)
            if len(parts) >= 3:
                frontmatter_text = parts[1].strip()
                frontmatter = {}
                
                for line in frontmatter_text.split('\n'):
                    if ':' in line and not line.strip().startswith('#'):
                        key, value = line.split(':', 1)
                        frontmatter[key.strip()] = value.strip().strip('"\'')
                
                body = parts[2].strip()
                return frontmatter, body
        except Exception as e:
            logger.warning(f"Frontmatter parsing error: {e}")
            
        return {}, content
    
    def enhance_frontmatter(self, frontmatter):
        """Enhance frontmatter with better Arabic translations"""
        
        enhanced = frontmatter.copy()
        
        # Enhanced title translations
        if 'title' in enhanced:
            enhanced['title'] = self.translate_text_intelligent(enhanced['title'])
        
        # Enhanced intro translations  
        if 'intro' in enhanced:
            enhanced['intro'] = self.translate_text_intelligent(enhanced['intro'])
            
        # Enhanced shortTitle translations
        if 'shortTitle' in enhanced:
            enhanced['shortTitle'] = self.translate_text_intelligent(enhanced['shortTitle'])
        
        # Ensure RTL direction for Arabic docs
        if 'dir' not in enhanced:
            enhanced['dir'] = 'rtl'
        return enhanced
    
    def translate_text_intelligent(self, text):
        """Intelligent text translation with context awareness"""
        
        if not text or not text.strip():
            return text
        
        # Preserve liquid tags and technical elements using stable placeholders
        temp_text = text
        preserved: List[Tuple[str, str]] = []  # (placeholder, original)
        
        def make_replacer(kind: str):
            def _repl(m: re.Match) -> str:
                placeholder = f"__PRESERVE_{kind}_{len(preserved)}__"
                preserved.append((placeholder, m.group(0)))
                return placeholder
            return _repl
        
        # Preserve liquid tags first
        liquid_pattern = r'({%[^%]*%}|{{[^}]*}})'
        temp_text = re.sub(liquid_pattern, make_replacer("LIQUID"), temp_text)
        
        # Preserve inline code snippets
        code_pattern = r'`[^`]+`'
        temp_text = re.sub(code_pattern, make_replacer("CODE"), temp_text)

        # Apply terminology translations
        for english, arabic in self.terminology.items():
            # Case-insensitive replacement with word boundaries
            pattern = r'\b' + re.escape(english) + r'\b'
            temp_text = re.sub(pattern, arabic, temp_text, flags=re.IGNORECASE)
            self.stats["terminology_applications"] += temp_text.count(arabic)

        # Apply linguistic rules
        for rule_category, rules in self.linguistic_rules.items():
            if rule_category == "technical_context":
                continue  # Skip technical context in this phase

            if isinstance(rules, dict) and "patterns" in rules:
                for pattern, replacement in rules["patterns"]:
                    if re.search(pattern, temp_text):
                        temp_text = re.sub(pattern, replacement, temp_text)
                        self.stats["pattern_matches"] += 1

        # If text still predominantly English, apply lexical fallback
        if self._arabic_ratio(temp_text) < self.fallback_threshold and len(re.findall(r"[A-Za-z]", temp_text)) > 50:
            temp_text = self._apply_lexical_fallback(temp_text)

        # Either restore preserved elements or drop them for Arabic-only output
        if self.arabic_only:
            for placeholder, _ in preserved:
                temp_text = temp_text.replace(placeholder, "")
            return self._arabic_only_cleanup(temp_text)
        else:
            for placeholder, original in preserved:
                temp_text = temp_text.replace(placeholder, original)
            return self._arabic_typography(temp_text)
    
    def generate_enhanced_content(self, original_content, frontmatter):
        """Generate enhanced Arabic content from English original"""
        
        # Start with Arabic header
        enhanced_content = f"# {frontmatter.get('title', 'Ù…Ø³ØªÙ†Ø¯ GitHub')}\n\n"
        
        # Add context-aware introduction
        if 'intro' in frontmatter:
            enhanced_content += f"{frontmatter['intro']}\n\n"
        
        # Analyze content structure
        sections = self.analyze_content_structure(original_content)
        
        # Generate intelligent Arabic content based on structure
        for section in sections:
            if section['type'] == 'heading':
                level = '#' * section['level']
                translated_heading = self.translate_text_intelligent(section['content'])
                enhanced_content += f"{level} {translated_heading}\n\n"
                
            elif section['type'] == 'paragraph':
                if section['content'].strip():
                    translated_paragraph = self.translate_text_intelligent(section['content'])
                    enhanced_content += f"{translated_paragraph}\n\n"
                    
            elif section['type'] == 'list':
                for item in section['items']:
                    translated_item = self.translate_text_intelligent(item)
                    enhanced_content += f"- {translated_item}\n"
                enhanced_content += "\n"
                
            elif section['type'] == 'code_block':
                enhanced_content += f"```{section.get('language', '')}\n{section['content']}\n```\n\n"
                
            elif section['type'] == 'quote':
                translated_quote = self.translate_text_intelligent(section['content'])
                enhanced_content += f"> {translated_quote}\n\n"
        
        # Add helpful Arabic navigation
        enhanced_content += "\n---\n\n"
        enhanced_content += "## Ù…ØµØ§Ø¯Ø± Ø¥Ø¶Ø§ÙÙŠØ©\n\n"
        enhanced_content += "- [Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù€ GitHub](https://docs.github.com/ar)\n"
        enhanced_content += "- [Ù…Ø¬ØªÙ…Ø¹ GitHub Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](https://github.com/community)\n"
        enhanced_content += "- [Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ](https://support.github.com)\n"
        
        return enhanced_content
    
    def analyze_content_structure(self, content):
        """Analyze content structure for intelligent processing"""
        
        sections = []
        lines = content.split('\n')
        
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            
            # Skip empty lines
            if not line:
                i += 1
                continue
            
            # Heading detection
            if line.startswith('#'):
                level = len(line) - len(line.lstrip('#'))
                heading_text = line.lstrip('#').strip()
                sections.append({
                    'type': 'heading',
                    'level': level,
                    'content': heading_text
                })
                
            # Code block detection
            elif line.startswith('```'):
                language = line[3:].strip()
                code_content = []
                i += 1
                while i < len(lines) and not lines[i].strip().startswith('```'):
                    code_content.append(lines[i])
                    i += 1
                sections.append({
                    'type': 'code_block',
                    'language': language,
                    'content': '\n'.join(code_content)
                })
                
            # List detection
            elif line.startswith(('-', '*', '+')):
                list_items = []
                while i < len(lines) and lines[i].strip().startswith(('-', '*', '+')):
                    item_text = lines[i].strip()[1:].strip()
                    list_items.append(item_text)
                    i += 1
                i -= 1  # Adjust for the increment at the end of the loop
                sections.append({
                    'type': 'list',
                    'items': list_items
                })
                
            # Quote detection
            elif line.startswith('>'):
                quote_text = line[1:].strip()
                sections.append({
                    'type': 'quote',
                    'content': quote_text
                })
                
            # Regular paragraph
            else:
                sections.append({
                    'type': 'paragraph',
                    'content': line
                })
            
            i += 1
        
        return sections
    
    def enhance_translation_file(self, arabic_file_path):
        """Enhance an existing Arabic translation file"""
        
        if not arabic_file_path.exists():
            logger.warning(f"Arabic file not found: {arabic_file_path}")
            return False
        
        try:
            # Read current Arabic content
            with open(arabic_file_path, 'r', encoding='utf-8') as f:
                current_content = f.read()
            
            # Extract frontmatter
            frontmatter, body = self.extract_frontmatter(current_content)
            
            # Find corresponding English file
            english_file_path = arabic_file_path.parent / arabic_file_path.name.replace('-ar.md', '.md')
            
            if english_file_path.exists():
                with open(english_file_path, 'r', encoding='utf-8') as f:
                    english_content = f.read()
                
                english_frontmatter, english_body = self.extract_frontmatter(english_content)
            else:
                english_body = ""
                english_frontmatter = {}
            
            # Enhance frontmatter
            enhanced_frontmatter = self.enhance_frontmatter(frontmatter)
            
            # Generate enhanced content
            enhanced_content = self.generate_enhanced_content(english_body, enhanced_frontmatter)
            
            # Construct final file content
            final_content = "---\n"
            for key, value in enhanced_frontmatter.items():
                # Preserve array and complex values
                if isinstance(value, (list, dict)):
                    final_content += f"{key}: {value}\n"
                else:
                    final_content += f"{key}: {value}\n"
            final_content += "---\n\n"
            final_content += (self._arabic_only_cleanup(enhanced_content) if self.arabic_only else self._arabic_typography(enhanced_content))
            
            # Write enhanced content
            with open(arabic_file_path, 'w', encoding='utf-8') as f:
                f.write(final_content)
            
            self.stats["files_processed"] += 1
            self.stats["translations_enhanced"] += 1
            
            logger.info(f"Enhanced: {arabic_file_path.name}")
            return True
            
        except Exception as e:
            logger.error(f"Error enhancing {arabic_file_path}: {e}")
            return False
    
    def enhance_sample_files(self, sample_size=5):
        """Enhance a sample of files for testing"""
        
        logger.info(f"Enhancing {sample_size} sample files...")
        
        # Find Arabic files
        arabic_files = list(self.content_root.rglob("*-ar.md"))
        
        if not arabic_files:
            logger.error("No Arabic files found to enhance")
            return False
        
        # Select random sample
        import random
        sample_files = random.sample(arabic_files, min(sample_size, len(arabic_files)))
        
        enhanced_count = 0
        for file_path in sample_files:
            if self.enhance_translation_file(file_path):
                enhanced_count += 1
        
        logger.info(f"Enhanced {enhanced_count}/{sample_size} sample files")
        self.print_enhancement_stats()
        
        return enhanced_count > 0
    
    def enhance_priority_files(self):
        """Enhance high-priority documentation files"""
        
        priority_patterns = [
            "*/index-ar.md",
            "*/README-ar.md", 
            "*get-started*-ar.md",
            "*authentication*-ar.md",
            "*actions*-ar.md",
            "*quick*-ar.md"
        ]
        
        priority_files = []
        for pattern in priority_patterns:
            priority_files.extend(self.content_root.glob(pattern))
            priority_files.extend(self.content_root.rglob(pattern))
        
        # Remove duplicates
        priority_files = list(set(priority_files))
        
        logger.info(f"Enhancing {len(priority_files)} priority files...")
        
        enhanced_count = 0
        for file_path in priority_files:
            if self.enhance_translation_file(file_path):
                enhanced_count += 1
        
        logger.info(f"Enhanced {enhanced_count}/{len(priority_files)} priority files")
        self.print_enhancement_stats()
        
        return enhanced_count > 0
    
    def enhance_all_files(self):
        """Enhance all Arabic translation files"""
        
        arabic_files = list(self.content_root.rglob("*-ar.md"))
        
        logger.info(f"Enhancing all {len(arabic_files)} Arabic files...")
        
        enhanced_count = 0
        for i, file_path in enumerate(arabic_files):
            if i % 100 == 0:
                logger.info(f"Progress: {i}/{len(arabic_files)} files processed...")
            
            if self.enhance_translation_file(file_path):
                enhanced_count += 1
        
        logger.info(f"Enhanced {enhanced_count}/{len(arabic_files)} files")
        self.print_enhancement_stats()
        
        return enhanced_count > 0
    
    def print_enhancement_stats(self):
        """Print enhancement statistics"""
        
        print("\nğŸ“Š LOCAL AI ENHANCEMENT STATISTICS")
        print("=" * 45)
        print(f"Files Processed: {self.stats['files_processed']}")
        print(f"Translations Enhanced: {self.stats['translations_enhanced']}")
        print(f"Terminology Applications: {self.stats['terminology_applications']}")
        print(f"Pattern Matches: {self.stats['pattern_matches']}")
        print(f"Linguistic Improvements: {self.stats['linguistic_improvements']}")
        
        # Calculate enhancement metrics
        if self.stats['files_processed'] > 0:
            avg_improvements = (
                self.stats['terminology_applications'] + 
                self.stats['pattern_matches'] + 
                self.stats['linguistic_improvements']
            ) / self.stats['files_processed']
            print(f"Average Improvements per File: {avg_improvements:.1f}")
        
        print("\nâœ… Local AI Enhancement Complete!")

def main():
    """Main function with command line interface"""
    
    import argparse
    
    parser = argparse.ArgumentParser(description="Local AI-Enhanced Translation")
    parser.add_argument("--sample", type=int, default=5, help="Number of sample files to enhance")
    parser.add_argument("--priority", action="store_true", help="Enhance priority files only")
    parser.add_argument("--all", action="store_true", help="Enhance all files")
    parser.add_argument("--file", type=str, help="Enhance a specific Arabic file path (e.g., docs/content/.../index-ar.md)")
    parser.add_argument("--root", type=str, help="Path to docs root (directory that contains 'content')")
    parser.add_argument("--aggressive", action="store_true", help="Use aggressive lexical fallback for stubborn files")
    parser.add_argument("--arabic-only", action="store_true", help="Output Arabic-only text (strip English/code/URLs)")
    
    args = parser.parse_args()
    
    # Initialize local AI translator
    translator = LocalAITranslator(docs_root=args.root, aggressive=args.aggressive, arabic_only=args.arabic_only)
    
    print("ğŸ¤– LOCAL AI-ENHANCED TRANSLATOR")
    print("=" * 40)
    print("âœ… No API key required!")
    print("âœ… 100% local processing!")
    print("âœ… Advanced linguistic intelligence!")
    print("âœ… Comprehensive terminology database!")
    
    if args.file:
        translator.enhance_translation_file(Path(args.file))
    elif args.all:
        translator.enhance_all_files()
    elif args.priority:
        translator.enhance_priority_files()
    else:
        translator.enhance_sample_files(args.sample)

if __name__ == "__main__":
    main()